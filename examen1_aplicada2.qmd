---
title: "Estadística Aplicada 3 - Examen 1"
lang: es
author: "Marcelino"
date: today
header-includes:
  - \usepackage{listings}
  - \usepackage{color} % si aún no lo has incluido; es necesario para \textcolor
  - \lstset{breaklines=true, postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space}}

format:
  html:
    page-layout: full
    embed-resources: true
---

```{r, message=FALSE, warning=FALSE}
#Cargamos paquetes
library(tidymodels)
library(discrim)
library(corrr)
library(paletteer)
library(MASS)
library(dslabs)
library(tidyr)

# Cargamos bases de datos
mnist_data <- read_mnist()
data2 <- iris
```

# Ejercicio 1

```{r,  message=FALSE, warning=FALSE, cache=TRUE}
#Extraer el train y test

## Preparamos los datos

### Entrenamiento y validacion
flattened_images <- matrix(mnist_data$train$images, nrow = dim(mnist_data$train$images)[1], ncol = 28*28)
df <- data.frame(label = mnist_data$train$labels)
df <- cbind(df, flattened_images)

### Testeo

flattened_images2 <- matrix(mnist_data$test$images, nrow = dim(mnist_data$test$images)[1], ncol = 28*28)
test_data <- data.frame(label = mnist_data$test$labels)
test_data <- cbind(test_data, flattened_images2)

## Transformar el train y test al estadístico que deseamos de solo 1, 3 y 5

df <- df  |> filter(label == 1 | label == 3 | label == 5)

test_data <- test_data |> filter(label == 1 | label == 3 | label == 5) # data testeo
test_data$label <- as.factor(test_data$label)

# Spliteamos datos de entrenamiento y validación para elegir el mejor modelo

set.seed(191654)
### Spliteamos la data para validación y entrenamiento
data_split <- rsample::initial_split(df, prop = .8, strata = "label")

train_data <- training(data_split) # data train
train_data$label <- as.factor(train_data$label)

val_data <- testing(data_split) # data validación
val_data$label <- as.factor(val_data$label)

# Preparación de datos para reducir dimensionalidad con PCA

# Preparamos motores de modelo

lda_spec <- discrim_linear() |>
  set_mode("classification") |>
  set_engine("MASS")

qda_spec <- discrim_quad() |>
  set_mode("classification") |>
  set_engine("MASS")

nb_spec <- naive_Bayes() |> 
  set_mode("classification") |> 
  set_engine("klaR") |> 
  set_args(usekernel = FALSE)

lr_spec <- logistic_reg() |>
  set_engine("glm") |>
  set_mode("classification")


# Preparamos recetas

rec <- recipe(label ~ ., data = train_data) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  step_pca(all_predictors(), num_comp = tune())


# Preparamos workflows

all_workflows <- workflow_set(
  preproc = list(receta =rec ), 
  models = list(LDA = lda_spec, QDA = qda_spec, NB = nb_spec, LR = lr_spec)
)

# Conjuntos de cross validation

cv <- vfold_cv(train_data, v = 7, strata = "label")

grid_vals <- tibble(num_comp = 1:100)

# Grid de hiperparámetros
grid_ctrl <-
  control_grid(
    save_pred = TRUE,
    parallel_over = "resamples",
    save_workflow = TRUE,
    verbose=TRUE,

  )

all_cores <- parallel::detectCores(logical = TRUE) - 3
library(doParallel)
cl <- makePSOCKcluster(all_cores)
registerDoParallel(cl)

system.time(
  grid_results <- all_workflows |>
    workflow_map(
      seed = 191654,
      resamples = cv,
      grid = grid_vals,
      control = grid_ctrl,
      verbose=TRUE,
      metrics=metric_set(recall, precision, accuracy, f_meas, roc_auc)
    )
)

### Estracción mejor modelo

#NB

best_resultsNBAYES <- 
  grid_results |> 
  extract_workflow_set_result("receta_NB") |> 
  select_best(metric = "roc_auc")

best_resultsNBAYES

NBAYES_test_results <- 
   grid_results |> 
   extract_workflow("receta_NB") |> 
   finalize_workflow(best_resultsNBAYES) |> 
   fit(base_train)

#LR

best_resultsLR <- 
  grid_results |> 
  extract_workflow_set_result("receta_LR") |> 
  select_best(metric = "roc_auc")

best_resultsLR

LR_test_results <- 
   grid_results |> 
   extract_workflow("receta_LR") |> 
   finalize_workflow(best_resultsLR) |> 
   fit(base_train)#NB


#QDA

best_resultsQDA <- 
  grid_results |> 
  extract_workflow_set_result("receta_QDA") |> 
  select_best(metric = "roc_auc")

best_resultsQDA

QDA_test_results <- 
   grid_results |> 
   extract_workflow("receta_QDA") |> 
   finalize_workflow(best_resultsQDA) |> 
   fit(base_train)

#LDA

best_resultsLDA <- 
  grid_results |> 
  extract_workflow_set_result("receta_LDA") |> 
  select_best(metric = "roc_auc")

best_resultsLDA

LDA_test_results <- 
   grid_results |> 
   extract_workflow("receta_LDA") |> 
   finalize_workflow(best_resultsLDA) |> 
   fit(base_train)



```



# Ejercicio 2

```{r}
library(cluster)

#Iris DB
data <- as.matrix(iris[,1:4])
dist_mat <- dist(data, method = 'euclidean')
```


```{r}
hclust_single <- hclust(dist_mat, method = 'single')
hclust_average <- hclust(dist_mat, method='average')
hclust_complete <- hclust(dist_mat, method= 'complete')
divisive_model <- agnes(dist_mat, method = "single")
```